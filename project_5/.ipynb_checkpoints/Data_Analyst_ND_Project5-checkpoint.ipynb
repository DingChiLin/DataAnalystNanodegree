{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Enron Submission Free-Response Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Summarize for us the goal of this project and how machine learning is useful in trying to accomplish it. As part of your answer, give some background on the dataset and how it can be used to answer the project question. Were there any outliers in the data when you got it, and how did you handle those? \n",
    "\n",
    "#### Goal： Using 146 financial data records which we already known whether they are person of interest or not to build a model that can predict if a person is 'poi' given the same financial features.\n",
    "\n",
    "#### Dataset Background:\n",
    "\n",
    "安融案件中，每個人的基本資料，並且有poi標註，還有一堆email。\n",
    "\n",
    "#### outliers:\n",
    "\n",
    "移除一個沒資訊的和TOTAL。\n",
    "\n",
    "移除 23 個超過 16 個Feature 是NaN且不是poi的，我只有21個feature （包含email），超過5/4是NaN的資料感覺上意義不大\n",
    "\n",
    "其他資料我不覺得算是outlier，可能有特別偏離的，但如果以要區分poi，或許這種資料正式我們想要的（例如salary特別高的就是poi)，移除他感覺很奇怪。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. What features did you end up using in your POI identifier, and what selection process did you use to pick them? Did you have to do any scaling? Why or why not? As part of the assignment, you should attempt to engineer your own feature that does not come ready-made in the dataset -- explain what feature you tried to make, and the rationale behind it. (You do not necessarily have to use it in the final analysis, only engineer and test it.) In your feature selection step, if you used an algorithm like a decision tree, please also give the feature importances of the features that you use, and if you used an automated feature selection function like SelectKBest, please report the feature scores and reasons for your choice of parameter values.\n",
    "\n",
    "我用的feature：exercised_stock_options, total_stock_value, pca_component1 （my own feature)\n",
    "\n",
    "\n",
    "scaling：使用了StandardScaler，因為某些演算法會被影響，且我有使用PCA去創作新feature，他也會被影響，不想用MixMax是因為有些極端直太大，會在成所有數字都變得很小，用標準差比較沒這問題，最後把變數都取小數點四位。\n",
    "\n",
    "新Feature：我用PCA創造了兩個變數，第一個變數（叫做pca_component1)應該會對在預測上有所貢獻，因為他的分數達到（），至於第二個變數應該影響不大，但我也將他加入測試，最後再SelectKBest得到的結果如我所預料。\n",
    "\n",
    "我用的selection process：Select K Best & naive naive_bayes 去測試取幾個比較剛好。（這幾個值的分數：...）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. What algorithm did you end up using? What other one(s) did you try? How did model performance differ between algorithms?\n",
    "\n",
    "嘗試了：naive_bayes, SVC, RandomForest, AdaBoost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4. What does it mean to tune the parameters of an algorithm, and what can happen if you don’t do this well?  How did you tune the parameters of your particular algorithm? (Some algorithms do not have parameters that you need to tune -- if this is the case for the one you picked, identify and briefly explain how you would have done it for the model that was not your final choice or a different model that does utilize parameter tuning, e.g. a decision tree classifier).\n",
    "\n",
    "參數調整意義：不同參數會改變演算法對分數的定義，或停止條件，因而影響演算法的速度和準確度。若沒調好可能會得到很差的結果，或者很慢的運算速度。\n",
    "\n",
    "我怎麼調參數的：使用GridSearchCV，對每個演算法重要的參數進行多種排列組合測試。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. What is validation, and what’s a classic mistake you can make if you do it wrong? How did you validate your analysis?\n",
    "\n",
    "什麼是驗證：依據得到的結果，給model一個分數來決定其好壞\n",
    "\n",
    "有什麼經典錯誤：如果只以accuracy判斷，在資料很多都是negative，很可能你的model只是把全部資料都當成negative，也能得到很高分數。\n",
    "\n",
    "我怎麼驗證：我想提昇recall，因為大多數的資料都是非poi，可能會犯上述經典錯誤，而我希望他能增加抓到poi的準確度，所以我拿recall_scorer當做GridSearchCV的判斷標準"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Give at least 2 evaluation metrics and your average performance for each of them.  Explain an interpretation of your metrics that says something human-understandable about your algorithm’s performance.\n",
    "\n",
    "evaluation metrics 1 : precession\n",
    "\n",
    "\n",
    "evaluation metrics 2 : recall\n",
    "\n",
    "\n",
    "從結果來看，在non-poi(negative）的部份判斷的非常準確，幾乎所有non-poi的都沒有被誤判。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
