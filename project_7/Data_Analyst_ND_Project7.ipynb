{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#A/B Test Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Metric Choice\n",
    "\n",
    "#### List which metrics you will use as invariant metrics and evaluation metrics here. (These should be the same metrics you chose in the \"Choosing Invariant Metrics\" and \"Choosing Evaluation Metrics\" quizzes.)\n",
    "\n",
    "1. Invariant metrics : Number of cookies, Number of clicks, Click-through-probability\n",
    "\n",
    "    Since the experiment make a change after users click the \"start free trial\" button and before enroll the course (by adding a message to notice the users the time commitment they are required), I would like the number of users be invariant before click the button, that is, the number of cookies view the course and the number of clicks of the button should be invariant. For the same reason, the number of user-ids of enrollment in free trial may changed after we add this notice and should not be put in the invariant metrics. Finally, the number of users click the button divide by the number of users view the course page (click-through-probability) should also be invariant since both the numerator and denominator are expected to be invariant.  <br/><br/>\n",
    "    \n",
    "2. Evaluaion metrics : Gross conversion, Net conversion\n",
    "\n",
    "    The goal of this experiment is to find out a way to reducing the number of frustrated students who left the free trial because they didn't have enough time without significantly reducing the number of students to continue past the free trial and eventually complete the course.\n",
    "        \n",
    "    I would like to see the change of retention since it directly relates to the experiment, I want to see a result that \"the number of users makes payment divide by the number of users enrolled the free trial\" grow in the experiment group. However, the needed pageviews are way too large and may lead to unacceptable experiment duration (more than 100 days). So I can't put it in my evaluation metrics.\n",
    "\n",
    "    Secondly, I want to reduces the rate of enrollment after we put the warning on it. This is part of the goal of this experiment. If I can make the number of enrollment down while keeping the number of payment unchanged, this experiment is worth launching. Both the gross conversion and number of user-ids can help me monitor this change, so I only need one of them. I choose gross conversion since the cookie in the control and experiment group may still have slight difference even I have choose it as one of the invariant metric. Dividing the number of user ids by the cookies who click the button can eliminate this little effect and make me see the rate of conversion more clearly. If I only look the change of user-ids of enrollment, there is a chance that both the number of cookies who click the button and the rate of user-ids enroll in free trial(gross conversion) change insignificantly in each group, but the change of user-ids change significantly by the addition of this two effect. In this case, I should not launch ths experiment, so this is not a good evaluation metric.\n",
    "    \n",
    "    Thirdly, I want the net conversion rate to be untouched or growth significantly, since this means the number of users who make payment, if the number of net conversion decrease significantly, I wouldn't like to launch this experiment.\n",
    "\n",
    "    Finally, The gross conversion and net conversion require reasonable pageviews to run the experiment, that is, I can finish this experiment within an acceptable time period, so these two metrics are chosen as my final evaluation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Measuring Standard Deviation\n",
    "\n",
    "#### List the standard deviation of each of your evaluation metrics. (These should be the answers from the \"Calculating standard deviation\" quiz.)\n",
    "\n",
    "1. Gross conversion : 0.0202 (400 clicks)\n",
    "2. Net conversion : 0.0156 (400 clicks)\n",
    "\n",
    "    I think the emperical variabiliy of gross conversion and net conversion would match with the analytic variability since the unit of analysis is cookie in each of the metric and the unit of diversion is also cookie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Sizing\n",
    "\n",
    "#### A. Number of Samples vs. Power \n",
    "####Indicate whether you will use the Bonferroni correction during your analysis phase, and give the number of pageviews you will need to power you experiment appropriately. (These should be the answers from the \"Calculating Number of Pageviews\" quiz.)\n",
    "\n",
    "1. Using bonferroni correction ? : No\n",
    "2. Needed Pageviews : 685325\n",
    "\n",
    "#### B . Duration vs. Exposure \n",
    "####Indicate what fraction of traffic you would divert to this experiment and, given this, how many days you would need to run the experiment. (These should be the answers from the \"Choosing Duration and Exposure\" quiz.)\n",
    "\n",
    "1. Fraction of traffic to divert : 1\n",
    "2. Days need to run the experiment : 18\n",
    "    \n",
    "    I don't think it will hurt the user by warning them the time they need to devote and I don't think this information is sensitive. Maybe we can get some general statistic result from it, I don't think any significant conclusion can be drawn for each individual user. So I will direct all users to this experiment and reduce the days we need to run it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Analysis\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Sanity Checks\n",
    "\n",
    "#### For each of your invariant metrics, give the 95% confidence interval for the value you expect to observe, the actual observed value, and whether the metric passes your sanity check. (These should be the answers from the \"Sanity Checks\" quiz.)\n",
    "\n",
    "| Invariant metrics          | Lower bound | Upper bound | Observed | Passes |\n",
    "|---|---|---|---|:-:|\n",
    "| Number of cookies          | 0.4988      | 0.5012      | 0.5006   | Yes    |\n",
    "| Number of clicks           | 0.4959      | 0.5041      | 0.5005   | Yes    |\n",
    "| Click-through-probability  | -0.0013     | 0.0013      | 0.0001   | Yes    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Result Analysis\n",
    "\n",
    "#### A. Effect Size Tests\n",
    "#### For each of your evaluation metrics, give a 95% confidence interval around the difference between the experiment and control groups. Indicate whether each metric is statistically and practically significant. (These should be the answers from the \"Effect Size Tests\" quiz.)\n",
    "\n",
    "| Evaluation metrics  | Lower bound | Upper bound | statistically significant | practically significant |\n",
    "|---|:-:|:-:|\n",
    "| Gross conversion    | -0.0291     | -0.0120     | Yes                       | Yes                     |\n",
    "| Net conversion      | -0.0116     | 0.0019      | No                        | No                      |\n",
    "\n",
    "\n",
    "#### B. Sign Tests\n",
    "#### For each of your evaluation metrics, do a sign test using the day-by-day data, and report the p-value of the sign test and whether the result is statistically significant. (These should be the answers from the \"Sign Tests\" quiz.)\n",
    "    \n",
    "| Evaluation metrics  | p-value | statistically significant |\n",
    "|---|:-:|:-:|\n",
    "| Gross conversion    | 0.0026  | Yes                       |\n",
    "| Net conversion      | 0.6776  | No                        |\n",
    "    \n",
    "#### C. Summary\n",
    "#### State whether you used the Bonferroni correction, and explain why or why not. If there are any discrepancies between the effect size hypothesis tests and the sign tests, describe the discrepancy and why you think it arose.\n",
    "\n",
    "1. using Bonferroni correction : No\n",
    "\n",
    "    The decision of launch this experiment or not is decided by both the gross conversion and net conversion. I will not launch the experiment if only one of the metric fulfill the condition. If only the gross conversion decrease significantly, I need to make sure the net conversion didn't decrease also, on the other hand, if the net conversion  increases significantly, I would like to double check my result by other experiments since it is not what I expect to see. So I don't need to use bonferroni correction. <br/><br/>\n",
    "\n",
    "2. There is no discrepancies between the effect size hypothesis tests and the sign tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Recommendation\n",
    "\n",
    "Basically, I will recommend launch this change based on the result of this experiment, since we see a practically significant decrease in the number of users enroll in the free trial and no statistically significant change in the number of users still enroll (and make payment) after the trial. This means we may improve the overall student experience and improve coaches' capacity to support students who are likely to complete the course without \"significantly\" reducing the number of students to continue past the free trial and eventually complete the course. That meet with the hypothesis we make at first place.\n",
    "\n",
    "However, one thing important is that the net conversion do have chance to go down a little since the confidence interval of it does include negative value (-1.16 %). Let me put it more clearly, the revenue may have chance to decrease within -1.16% or increase within 0.19% (The probability of decresing or increasing more than this boundary is only 2.5% each). Although this experiment result is positive, the business team should think about whether the chance of decreasing revenue in this amount is acceptable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow-Up Experiment\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Give a high-level description of the follow up experiment you would run, what your hypothesis would be, what metrics you would want to measure, what your unit of diversion would be, and your reasoning for these choices.\n",
    "\n",
    "In the baseline information, most of the people drop out after clicking \"start free trial\" and before enrolling the course. The only things happen between this two events is asking users to enter their credit card information and the warning of time-consuming after launching this experiment. I would like to try to move the timing of asking credit card information from the beginning to the end of the free trial, that is, asking after they finish their 14-days free trial. I think this will increase the enrollment rate hugely and increase the payment rate slightly, since some people may feel like to keep going after trying 14 days, and those who don't think this course helpful will not keep paying no matter how.\n",
    "\n",
    "1. Hypothesis : moving the timing of asking credit card information from the beginning of the free trial to the end of it will increase the rate of enrollment and payment. <br/><br/> \n",
    "2. Metrics : \n",
    "    1. Invariant metrics : All invariants are set because I want there are equal number of pageviews and clicks in the control and experiment group.\n",
    "    \n",
    "        1. Number of cookies : The number of unique cookies to view the course overview page.\n",
    "        2. Number of clicks : The number of unique cookies to click the \"Start free trial\" button.\n",
    "        3. Click-through-probability : The number of unique cookies to click the \"Start free trial\" button divided by the number of unique cookies to view the course overview page.    \n",
    "    \n",
    "    2. Evaluation metrics : The first evaluation metric will test the increase rate of enrollment, the second will test the increase of payment, My guess is that this change will make a great improvement of enrollment rate and some improvement of payment rate. \n",
    "    \n",
    "        1. Gross conversion : the number of user-ids to enroll in the free trial divided by the number of unique cookies to click the \"Start free trial\" button. (dmin = 0.05)\n",
    "        2. Net conversion : the number of user-ids to remain enrolled past the 14-day boundary divided by the number of unique cookies to click the \"Start free trial\" button. (dmin = 0.01) <br/><br/> \n",
    "       \n",
    "3. Unit of diversion : Since I'm testing the user behavior about clicking \"free trial\" button and further movements, some user may not have user-id when clicking the button, so I need to use the cookie to be my unit of diversion."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
